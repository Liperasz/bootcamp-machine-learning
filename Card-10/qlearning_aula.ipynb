{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c848e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m:\u001b[43m \u001b[0m| : :\u001b[34;1mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# biblioteca que tem o joguinho do taxi\n",
    "import gym\n",
    "import random\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# criando o ambiente do taxi\n",
    "streets = gym.make(\"Taxi-v3\", render_mode='ansi').env\n",
    "\n",
    "# resetando o ambiente\n",
    "streets.reset()\n",
    "# mostra o estado atual do jogo\n",
    "print('\\n' + streets.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e971a4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[35m\u001b[43mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# definindo um estado inicial específico \n",
    "# linha do taxi, coluna do taxi, passageiro, destino\n",
    "initial_state = streets.encode(2, 3, 2, 0)\n",
    "\n",
    "streets.s = initial_state # coloca o ambiente atual no estado inicial definido\n",
    "\n",
    "streets.reset() # reseta o ambiente\n",
    "print('\\n' + streets.render()) # mostra o estado atual do jogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d72f6be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 368, -1, False)],\n",
       " 1: [(1.0, 168, -1, False)],\n",
       " 2: [(1.0, 288, -1, False)],\n",
       " 3: [(1.0, 248, -1, False)],\n",
       " 4: [(1.0, 268, -10, False)],\n",
       " 5: [(1.0, 268, -10, False)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostra a tabela Q com: probabilidade de cada ação, próximo estado, pontuação e estado do jogp\n",
    "streets.P[initial_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# cria uma tabela Q zerada, com o número de estados e ações possíveis\n",
    "q_table = np.zeros([streets.observation_space.n, streets.action_space.n])\n",
    "\n",
    "learning_rate = 0.1 # taxa de aprendizado, evita que o taxi mude de opinão facilmente\n",
    "discount_factor = 0.6 # valorização das recompensas\n",
    "exploration = 0.1 # a chance de tomar uma decisão aleatória inves de uma já conhecida\n",
    "epochs = 10000 # número de partidas para treinar\n",
    "\n",
    "for taxi_run in range(epochs):\n",
    "\n",
    "    state = streets.reset()[0] # reinicia o jogo e pega o estado inicial\n",
    "    done = False\n",
    "\n",
    "    while not done: # enquanto não tiver acabado\n",
    "        \n",
    "        random_value = random.uniform(0, 1) # gera uma probabilidade aleatória\n",
    "\n",
    "        if (random_value < exploration): # decide se vai explorar ou manter um caminho conhecido\n",
    "            action = streets.action_space.sample() # a função sample() escolhe uma ação aleatória\n",
    "\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) # olha a linha da tabela q da posição em que ele está e escolhe a ação com maior valor\n",
    "\n",
    "        # move o taxi\n",
    "        # next_state é o lugar onde o taxi parou\n",
    "        # reward é a pontuação que ele recebeu\n",
    "        # terminated ou truncated indicam se o jogo acabou\n",
    "        next_state, reward, terminated, truncated, info = streets.step(action) \n",
    "\n",
    "        # verifica se o jogo acabou\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        # pega o valor antigo da tabela\n",
    "        prev_q = q_table[state, action]\n",
    "\n",
    "        # atualiza a tabela Q usando a formula de qlearning\n",
    "        next_max_q = np.max(q_table[next_state])\n",
    "        new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q)\n",
    "        q_table[state, action] = new_q\n",
    "\n",
    "        # atualiza a posição do taxi\n",
    "        state = next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a9662b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.42792015, -2.42592733, -2.41888932, -2.3639511 , -8.39843486,\n",
       "       -6.87487463])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostra as notas da tabela para o estado inicial\n",
    "q_table[initial_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e9f5c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip number10\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35m\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# biblioteca visual do jupyter\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "# numero da viagem\n",
    "for tripnum in range(1, 11):\n",
    "\n",
    "    # pega o estado inicial\n",
    "    state = streets.reset()[0]\n",
    "\n",
    "    done = False\n",
    "\n",
    "    # enquanto nao tiver acabado\n",
    "    while not done:\n",
    "\n",
    "        # a ação é a que tem maior valor na tabela Q\n",
    "        action = np.argmax(q_table[state])\n",
    "\n",
    "        # faz a ação\n",
    "        next_state, reward, terminated, truncated, info = streets.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # espera um pouco e limpa a tela para mostrar o próximo estado\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # mostra o número da viagem e o estado atual do jogo\n",
    "        print(\"Trip number\" + str(tripnum))\n",
    "\n",
    "        # mostra o jogo\n",
    "        print(streets.render())\n",
    "\n",
    "        # espera\n",
    "        sleep(.5)\n",
    "\n",
    "        # passa para o próximo estado\n",
    "        state = next_state\n",
    "\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd2964d",
   "metadata": {},
   "source": [
    "### Your Challenge\n",
    "\n",
    "Modify the block above to keep track of the total time steps, and use that as a metric as to how good our Q-learning system is. You might want to increase the number of simulated trips, and remove the sleep() calls to allow you to run over more samples\n",
    "\n",
    "Now, try experimenting with the hyperparameters. How low can the number of epochs go before our model starts to suffer? Can you come up with better learning rates, discount factors, or exploration factors to make the training more efficient? The exploration vs exploitation rate in particular is interesting to experiment with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cda199ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(trips):\n",
    "\n",
    "    steps = 0\n",
    "\n",
    "    for _ in range(trips):\n",
    "\n",
    "        # pega o estado inicial\n",
    "        state = streets.reset()[0]\n",
    "        done = False\n",
    "\n",
    "        # enquanto nao tiver acabado\n",
    "        while not done:\n",
    "\n",
    "            # a ação é a que tem maior valor na tabela Q\n",
    "            action = np.argmax(q_table[state])\n",
    "\n",
    "            # faz a ação\n",
    "            next_state, reward, terminated, truncated, info = streets.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # atualiza o número de passos\n",
    "            steps += 1\n",
    "\n",
    "            # passa para o próximo estado\n",
    "            state = next_state\n",
    "\n",
    "    avg_step = steps / trips\n",
    "    print(\"Average steps per trip: {}\".format(avg_step))\n",
    "    return avg_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d15456",
   "metadata": {},
   "source": [
    "Chegou a um ponto em que eu tive que interromper o taxi, o motivo é simples: ele estava perdido, o treinamento não foi o suficiente para que ele conseguisse realizar todos os caminhos, ele provavelmente está se perdendo no meio e eu não coloquei nenhum limite de tempo ou algo do tipo para interrupção"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cddb0f6",
   "metadata": {},
   "source": [
    "No próximo bloco vou fazer algumas mudanças no código de treinamento que está lá encima.\n",
    "Colocarei apenas os comentários nas alterações feitas, e excluirei os comentários antigos para evitar poluição visual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f5f25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "q_table = np.zeros([streets.observation_space.n, streets.action_space.n])\n",
    "\n",
    "learning_rate = 0.075 # diminui a taxa de aprendizado para ver se ele se torna mais estável\n",
    "discount_factor = 0.8 # aumentei a taxa de desconto, para que ele valorize as recompensas futuras \n",
    "exploration = 0.25 # aumentei os indices de descobrimento para que ele explore mais o ambiente\n",
    "epochs = 30000 # tripliquei o número de treinamentos \n",
    "\n",
    "for taxi_run in range(epochs):\n",
    "\n",
    "    state = streets.reset()[0] \n",
    "    done = False\n",
    "\n",
    "    while not done: \n",
    "        \n",
    "        random_value = random.uniform(0, 1) \n",
    "\n",
    "        if (random_value < exploration): \n",
    "            action = streets.action_space.sample() \n",
    "\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) \n",
    "\n",
    "        next_state, reward, terminated, truncated, info = streets.step(action) \n",
    "\n",
    "        done = terminated or truncated\n",
    "        prev_q = q_table[state, action]\n",
    "        next_max_q = np.max(q_table[next_state])\n",
    "        new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q)\n",
    "        q_table[state, action] = new_q\n",
    "\n",
    "        state = next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f40f63c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average steps per trip: 13.006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.006"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ef039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
